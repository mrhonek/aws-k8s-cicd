name: EKS Direct Deployment

on:
  push:
    branches: [ main ]
  workflow_dispatch:

env:
  AWS_REGION: us-west-1
  ECR_REPOSITORY: portfolio-app
  EKS_CLUSTER_NAME: portfolio-cluster
  ACCOUNT_ID: "537124942860"

permissions:
  id-token: write
  contents: read

jobs:
  deploy:
    name: Deploy to EKS
    runs-on: ubuntu-latest

    steps:
    - name: Checkout Repository
      uses: actions/checkout@v4

    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        role-to-assume: arn:aws:iam::537124942860:role/github-actions-role
        aws-region: us-west-1
        audience: sts.amazonaws.com
        role-session-name: GitHubActions

    - name: Debug AWS Role and Credentials
      run: |
        echo "Checking AWS identity..."
        aws sts get-caller-identity
        AWS_ROLE=$(aws sts get-caller-identity --query "Arn" --output text)
        echo "Current AWS Role: $AWS_ROLE"
        
        # List current IAM permissions
        echo "Checking IAM permissions..."
        aws iam list-attached-role-policies --role-name github-actions-role || echo "Could not list role policies"
        
        # Check EKS access
        echo "Checking EKS access..."
        aws eks list-clusters

    - name: Setup kubectl
      run: |
        echo "Installing kubectl..."
        curl -LO "https://dl.k8s.io/release/v1.28.1/bin/linux/amd64/kubectl"
        chmod +x kubectl
        sudo mv kubectl /usr/local/bin/
        kubectl version --client
        
        # Install aws-iam-authenticator
        echo "Installing aws-iam-authenticator..."
        curl -Lo aws-iam-authenticator https://github.com/kubernetes-sigs/aws-iam-authenticator/releases/download/v0.6.11/aws-iam-authenticator_0.6.11_linux_amd64
        chmod +x ./aws-iam-authenticator
        sudo mv ./aws-iam-authenticator /usr/local/bin/
        aws-iam-authenticator version

    - name: Install Helm
      run: |
        echo "Installing Helm..."
        curl -fsSL -o get_helm.sh https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3
        chmod 700 get_helm.sh
        ./get_helm.sh
        helm version

    - name: Connect to EKS
      run: |
        echo "Connecting to EKS..."
        
        # Show current AWS identity
        echo "Current AWS identity:"
        aws sts get-caller-identity
        
        # Extract the IAM role being used
        ROLE_ARN=$(aws sts get-caller-identity --query 'Arn' --output text)
        echo "Role ARN: $ROLE_ARN"
        
        # Extract just the role name if it's an assumed role
        if [[ "$ROLE_ARN" == *":assumed-role/"* ]]; then
          ROLE_NAME=$(echo $ROLE_ARN | awk -F'/' '{print $2}')
          ROLE_SESSION=$(echo $ROLE_ARN | awk -F'/' '{print $3}')
          echo "Assumed Role Name: $ROLE_NAME"
          echo "Session Name: $ROLE_SESSION"
          
          # For documentation purposes, construct the IAM role ARN format needed for aws-auth
          ACCOUNT_ID=$(aws sts get-caller-identity --query 'Account' --output text)
          IAM_ROLE_ARN="arn:aws:iam::${ACCOUNT_ID}:role/${ROLE_NAME}"
          echo "IAM Role ARN for aws-auth: $IAM_ROLE_ARN"
          
          # Save this for the documentation step
          echo "IAM_ROLE_ARN=${IAM_ROLE_ARN}" >> $GITHUB_ENV
        fi
        
        # Verify role has EKS access
        echo "Verifying EKS permissions..."
        aws eks describe-cluster --name ${EKS_CLUSTER_NAME} --region ${AWS_REGION} || echo "Failed to describe cluster"
        
        # Generate kubeconfig using the authenticator directly for debugging
        echo "Generating kubeconfig..."
        aws eks update-kubeconfig --name ${EKS_CLUSTER_NAME} --region ${AWS_REGION} --verbose
        
        # Print the generated token for debugging (safety: this will not actually print any sensitive info)
        echo "Debugging token generation:"
        aws eks get-token --cluster-name ${EKS_CLUSTER_NAME} --region ${AWS_REGION} | grep -v token
        
        # Get cluster info
        echo "Verifying EKS connection..."
        kubectl config view
        KUBECONFIG=$(kubectl config view --minify -o jsonpath='{.clusters[0].cluster.server}')
        echo "Cluster API Server: $KUBECONFIG"
        
        # Pre-authenticate for kubectl
        echo "Pre-authenticating..."
        TOKEN=$(aws eks get-token --cluster-name ${EKS_CLUSTER_NAME} --region ${AWS_REGION} | jq -r '.status.token')
        echo "Token generated (not showing for security)"
        
        # Try with token
        echo "Testing with explicit token..."
        kubectl --token="${TOKEN}" cluster-info || echo "Explicit token failed"
        
        # Try a different approach with environment variables
        echo "Trying with environment variables..."
        export AWS_EKS_CLUSTER=${EKS_CLUSTER_NAME}
        export AWS_REGION=${AWS_REGION}
        kubectl cluster-info || echo "Failed to connect to cluster"
        
        # Check aws-auth configmap
        echo "Checking aws-auth ConfigMap..."
        kubectl get configmap aws-auth -n kube-system || echo "Could not get aws-auth ConfigMap"
        
        # Try to list nodes
        echo "Trying to list nodes..."
        kubectl get nodes || echo "Failed to get nodes"

    - name: Manually Save ECR Info
      run: |
        echo "Setting up ECR info..."
        ECR_URI="${ACCOUNT_ID}.dkr.ecr.${AWS_REGION}.amazonaws.com/${ECR_REPOSITORY}"
        echo "ECR_URI=$ECR_URI" >> $GITHUB_ENV
        echo "IMAGE_TAG=${{ github.sha }}" >> $GITHUB_ENV
        echo "Full image reference: ${ECR_URI}:${{ github.sha }}"

    - name: Deploy App
      run: |
        echo "Deploying application with Helm..."
        
        # Set explicit full image URL
        FULL_IMAGE_URL="${ACCOUNT_ID}.dkr.ecr.${AWS_REGION}.amazonaws.com/${ECR_REPOSITORY}:${IMAGE_TAG}"
        echo "Full image URL: $FULL_IMAGE_URL"
        
        # Create namespace
        kubectl create namespace prod --dry-run=client -o yaml | kubectl apply -f -
        
        # Check Helm chart directory
        echo "Checking Helm chart directory..."
        ls -la ./kubernetes/helm/app
        
        # Check Helm chart values
        echo "Checking Helm chart values..."
        cat ./kubernetes/helm/app/values.yaml
        
        # Create a temporary values file with our specific overrides
        cat > ./custom-values.yaml << EOF
        image:
          repository: "${ACCOUNT_ID}.dkr.ecr.${AWS_REGION}.amazonaws.com/${ECR_REPOSITORY}"
          tag: "${IMAGE_TAG}"
        EOF
        
        echo "Custom values file:"
        cat ./custom-values.yaml
        
        # Deploy with Helm using values file instead of --set
        helm upgrade --install portfolio-app ./kubernetes/helm/app \
          -f ./custom-values.yaml \
          --namespace prod \
          --create-namespace \
          --debug
        
        # Check deployment
        kubectl get pods -n prod
        kubectl get services -n prod
        
        # Get LoadBalancer URL for Slack notification
        echo "Getting LoadBalancer URL..."
        LOADBALANCER_URL=$(kubectl get svc -n prod portfolio-app -o jsonpath='{.status.loadBalancer.ingress[0].hostname}')
        echo "LoadBalancer URL: $LOADBALANCER_URL"
        echo "APP_URL=http://$LOADBALANCER_URL" >> $GITHUB_ENV

    - name: Notify Result
      run: |
        echo "Deployment completed."
        echo "GitHub SHA: ${{ github.sha }}"
        echo "ECR URI: ${ECR_URI}"
        echo "App URL: ${{ env.APP_URL }}"
        
    # New steps for Slack notifications
    - name: Notify Slack on Success
      if: success()
      uses: slackapi/slack-github-action@v1.25.0
      with:
        payload: |
          {
            "text": "‚úÖ Deployment Successful! üöÄ",
            "blocks": [
              {
                "type": "header",
                "text": {
                  "type": "plain_text",
                  "text": "‚úÖ EKS Deployment Successful! üöÄ",
                  "emoji": true
                }
              },
              {
                "type": "section",
                "text": {
                  "type": "mrkdwn",
                  "text": "*Repository:* ${{ github.repository }}\n*Branch:* ${{ github.ref_name }}\n*Commit SHA:* ${{ github.sha }}"
                }
              },
              {
                "type": "section",
                "text": {
                  "type": "mrkdwn",
                  "text": "*ECR Image:* ${ECR_URI}:${{ github.sha }}"
                }
              },
              {
                "type": "section",
                "text": {
                  "type": "mrkdwn",
                  "text": "*üåê Application URL:* <${{ env.APP_URL }}|${{ env.APP_URL }}>"
                }
              },
              {
                "type": "actions",
                "elements": [
                  {
                    "type": "button",
                    "text": {
                      "type": "plain_text",
                      "text": "View Workflow Run",
                      "emoji": true
                    },
                    "url": "https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }}"
                  },
                  {
                    "type": "button",
                    "text": {
                      "type": "plain_text",
                      "text": "Open Application",
                      "emoji": true
                    },
                    "url": "${{ env.APP_URL }}"
                  }
                ]
              }
            ]
          }
      env:
        SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}
        SLACK_WEBHOOK_TYPE: INCOMING_WEBHOOK

    - name: Notify Slack on Failure
      if: failure()
      uses: slackapi/slack-github-action@v1.25.0
      with:
        payload: |
          {
            "text": "‚ùå Deployment Failed",
            "blocks": [
              {
                "type": "header",
                "text": {
                  "type": "plain_text",
                  "text": "‚ùå EKS Deployment Failed",
                  "emoji": true
                }
              },
              {
                "type": "section",
                "text": {
                  "type": "mrkdwn",
                  "text": "*Repository:* ${{ github.repository }}\n*Branch:* ${{ github.ref_name }}\n*Commit SHA:* ${{ github.sha }}"
                }
              },
              {
                "type": "actions",
                "elements": [
                  {
                    "type": "button",
                    "text": {
                      "type": "plain_text",
                      "text": "View Workflow Run",
                      "emoji": true
                    },
                    "url": "https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }}"
                  }
                ]
              }
            ]
          }
      env:
        SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}
        SLACK_WEBHOOK_TYPE: INCOMING_WEBHOOK

    - name: Create Documentation for EKS Role Binding (if deployment fails)
      if: failure()
      run: |
        echo "It appears that the GitHub Actions role may not have the necessary permissions in your EKS cluster."
        echo "Here's what you need to do to fix the authentication issue:"
        echo ""
        echo "1. On your local machine with admin access to the EKS cluster, run these commands:"
        echo ""
        echo "# Get the existing aws-auth ConfigMap"
        echo "kubectl get configmap aws-auth -n kube-system -o yaml > aws-auth-configmap.yaml"
        echo ""
        echo "# Edit the ConfigMap to add the GitHub Actions role"
        echo "# Add this to the 'mapRoles' section:"
        echo "  - rolearn: ${IAM_ROLE_ARN:-arn:aws:iam::537124942860:role/github-actions-role}"
        echo "    username: github-actions"
        echo "    groups:"
        echo "      - system:masters"
        echo ""
        echo "# Apply the updated ConfigMap"
        echo "kubectl apply -f aws-auth-configmap.yaml"
        echo ""
        echo "2. After updating the ConfigMap, re-run this workflow."
        echo ""
        echo "For more information, see the AWS documentation:"
        echo "https://docs.aws.amazon.com/eks/latest/userguide/add-user-role.html"
        
        # Create a documentation file without the heredoc syntax to avoid YAML linting issues
        mkdir -p ./docs
        {
          echo "# Fixing EKS Authentication for GitHub Actions"
          echo ""
          echo "If the GitHub Actions workflow fails with an error message like:"
          echo "> \"the server has asked for the client to provide credentials\""
          echo ""
          echo "You need to add the GitHub Actions IAM role to the EKS cluster's authorization ConfigMap."
          echo ""
          echo "## Steps to Fix"
          echo ""
          echo "1. Make sure you have \`kubectl\` installed and configured to access your EKS cluster."
          echo ""
          echo "2. Run the following commands:"
          echo ""
          echo "\`\`\`bash"
          echo "# Get the existing aws-auth ConfigMap"
          echo "kubectl get configmap aws-auth -n kube-system -o yaml > aws-auth-configmap.yaml"
          echo ""
          echo "# Edit aws-auth-configmap.yaml and add the following to the mapRoles section:"
          echo "# - rolearn: arn:aws:iam::537124942860:role/github-actions-role"
          echo "#   username: github-actions"
          echo "#   groups:"
          echo "#     - system:masters"
          echo ""
          echo "# Then apply the updated ConfigMap"
          echo "kubectl apply -f aws-auth-configmap.yaml"
          echo "\`\`\`"
          echo ""
          echo "3. Verify that the role has been added correctly:"
          echo ""
          echo "\`\`\`bash"
          echo "kubectl get configmap aws-auth -n kube-system -o yaml"
          echo "\`\`\`"
          echo ""
          echo "4. Re-run the GitHub Actions workflow."
          echo ""
          echo "## Example aws-auth ConfigMap"
          echo ""
          echo "\`\`\`yaml"
          echo "apiVersion: v1"
          echo "kind: ConfigMap"
          echo "metadata:"
          echo "  name: aws-auth"
          echo "  namespace: kube-system"
          echo "data:"
          echo "  mapRoles: |"
          echo "    - rolearn: arn:aws:iam::537124942860:role/EKS-NodeInstanceRole"
          echo "      username: system:node:{{EC2PrivateDNSName}}"
          echo "      groups:"
          echo "        - system:bootstrappers"
          echo "        - system:nodes"
          echo "    - rolearn: ${IAM_ROLE_ARN:-arn:aws:iam::537124942860:role/github-actions-role}"
          echo "      username: github-actions"
          echo "      groups:"
          echo "        - system:masters"
          echo "\`\`\`"
          echo ""
          echo "For more information, see the [AWS documentation](https://docs.aws.amazon.com/eks/latest/userguide/add-user-role.html)."
        } > ./docs/eks-auth-fix.md 