name: Deploy with Helm

on:
  push:
    branches: [ main ]
  workflow_dispatch:

env:
  AWS_REGION: us-west-1
  ECR_REPOSITORY: portfolio-app
  EKS_CLUSTER_NAME: portfolio-cluster

permissions:
  id-token: write
  contents: read

jobs:
  deploy:
    name: Deploy to EKS
    runs-on: ubuntu-latest

    steps:
    - name: Checkout Repository
      uses: actions/checkout@v4

    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        role-to-assume: arn:aws:iam::537124942860:role/github-actions-role
        aws-region: us-west-1
        audience: sts.amazonaws.com
        role-session-name: GitHubActions

    - name: Verify AWS Authentication
      run: |
        echo "Verifying AWS Authentication..."
        aws sts get-caller-identity
        echo "Listing EKS clusters..."
        aws eks list-clusters

    - name: Login to Amazon ECR
      id: login-ecr
      uses: aws-actions/amazon-ecr-login@v2

    - name: Install kubectl
      uses: azure/setup-kubectl@v3
      with:
        version: 'v1.28.1' # Or whichever version you prefer

    - name: Install Helm
      uses: azure/setup-helm@v3
      with:
        version: 'v3.12.1' # Or whichever version you prefer

    - name: Set up kubeconfig with direct token authentication
      run: |
        echo "Setting up kubeconfig with explicit session token..."
        
        # Get EKS cluster endpoint
        CLUSTER_ENDPOINT=$(aws eks describe-cluster --name ${{ env.EKS_CLUSTER_NAME }} --region ${{ env.AWS_REGION }} --query "cluster.endpoint" --output text)
        echo "Cluster endpoint: $CLUSTER_ENDPOINT"
        
        # Get cluster CA certificate
        CERTIFICATE_DATA=$(aws eks describe-cluster --name ${{ env.EKS_CLUSTER_NAME }} --region ${{ env.AWS_REGION }} --query "cluster.certificateAuthority.data" --output text)
        echo "Retrieved cluster CA certificate"
        
        # Get token for kubectl
        TOKEN=$(aws eks get-token --cluster-name ${{ env.EKS_CLUSTER_NAME }} --region ${{ env.AWS_REGION }} | jq -r '.status.token')
        echo "Retrieved authentication token"
        
        # Set up kubeconfig manually
        mkdir -p $HOME/.kube
        cat > $HOME/.kube/config << EOF
        apiVersion: v1
        clusters:
        - cluster:
            certificate-authority-data: $CERTIFICATE_DATA
            server: $CLUSTER_ENDPOINT
          name: ${{ env.EKS_CLUSTER_NAME }}
        contexts:
        - context:
            cluster: ${{ env.EKS_CLUSTER_NAME }}
            user: aws-eks
          name: ${{ env.EKS_CLUSTER_NAME }}
        current-context: ${{ env.EKS_CLUSTER_NAME }}
        kind: Config
        preferences: {}
        users:
        - name: aws-eks
          user:
            token: $TOKEN
        EOF
        
        echo "Kubeconfig created successfully"
        
        # Test kubectl connectivity
        kubectl cluster-info
        
        # Verify the ConfigMap exists (will create it if it doesn't)
        kubectl get configmap aws-auth -n kube-system || {
          echo "Creating aws-auth ConfigMap..."
          cat > aws-auth-cm.yaml << EOF
        apiVersion: v1
        kind: ConfigMap
        metadata:
          name: aws-auth
          namespace: kube-system
        data:
          mapRoles: |
            - rolearn: arn:aws:iam::537124942860:role/github-actions-role
              username: github-actions
              groups:
                - system:masters
        EOF
          kubectl apply -f aws-auth-cm.yaml
          echo "aws-auth ConfigMap created"
        }
        
        # Update aws-auth ConfigMap if it exists
        if kubectl get configmap aws-auth -n kube-system -o yaml | grep -q "mapRoles"; then
          echo "Updating existing aws-auth ConfigMap..."
          
          # Get the current ConfigMap and modify it
          kubectl get configmap aws-auth -n kube-system -o yaml | sed '/mapRoles/,/kind/!b;/kind/!d;/kind/i\    - rolearn: arn:aws:iam::537124942860:role/github-actions-role\n      username: github-actions\n      groups:\n        - system:masters' > aws-auth-update.yaml
          
          # Apply the updated ConfigMap
          kubectl apply -f aws-auth-update.yaml
          echo "Updated aws-auth ConfigMap"
        fi
        
        # Display the aws-auth ConfigMap
        echo "Current aws-auth ConfigMap:"
        kubectl get configmap aws-auth -n kube-system -o yaml

    - name: Debug Environment
      run: |
        echo "Using EKS Cluster: ${{ env.EKS_CLUSTER_NAME }}"
        echo "AWS Region: ${{ env.AWS_REGION }}"
        echo "Current directory: $(pwd)"
        ls -la ./kubernetes/helm/app || echo "Helm chart directory not found"
        
    - name: Deploy with Helm
      env:
        ECR_REGISTRY: ${{ steps.login-ecr.outputs.registry }}
        IMAGE_TAG: ${{ github.sha }}
      run: |
        # Debug information
        echo "Using ECR Registry: $ECR_REGISTRY"
        echo "Using Image Tag: $IMAGE_TAG"
        echo "Using release name: portfolio-app"
        
        # Set full image repository path with validation
        if [ -z "$ECR_REGISTRY" ]; then
          echo "ERROR: ECR_REGISTRY is empty!"
          exit 1
        fi
        
        FULL_IMAGE_REPO="${ECR_REGISTRY}/${{ env.ECR_REPOSITORY }}"
        echo "Full image repository: $FULL_IMAGE_REPO"
        
        # Test authentication again right before Helm deployment
        echo "Testing Kubernetes authentication again before deployment:"
        kubectl get nodes
        kubectl get namespace prod || kubectl create namespace prod
        
        # Use Helm to deploy the application
        echo "Deploying with Helm..."
        helm upgrade --install portfolio-app ./kubernetes/helm/app \
          --set image.repository=${FULL_IMAGE_REPO} \
          --set image.tag=$IMAGE_TAG \
          --namespace prod
        
        # Verify deployment
        kubectl get pods -n prod
        kubectl rollout status deployment/portfolio-app -n prod --timeout=60s
        
    - name: Notify Slack
      uses: 8398a7/action-slack@v3
      with:
        status: ${{ job.status }}
        fields: repo,message,commit,author,action,eventName,ref,workflow,job,took
      env:
        SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}
      if: always()